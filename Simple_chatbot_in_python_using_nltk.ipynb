{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBvaMVAp7FcH",
        "outputId": "f875000e-7bc0-4ee5-8872-957e309ebe69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Install NLTK\n",
        "!pip install nltk scikit-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create chatbot.txt with responses\n",
        "chatbot_text = \"\"\"\n",
        "hi\n",
        "hello\n",
        "hey there\n",
        "how are you\n",
        "i am a chatbot, always happy to help you!\n",
        "what is your name\n",
        "i am a simple chatbot created to chat with you.\n",
        "who created you\n",
        "i was created by developers using python and nltk.\n",
        "what can you do\n",
        "i can chat with you and answer simple questions.\n",
        "tell me about python\n",
        "python is a high-level, interpreted programming language known for its simplicity and readability.\n",
        "tell me about nltk\n",
        "nltk is a leading platform for building python programs to work with human language data.\n",
        "bye\n",
        "goodbye! see you soon.\n",
        "\"\"\"\n",
        "\n",
        "with open('chatbot.txt', 'w') as f:\n",
        "    f.write(chatbot_text)\n"
      ],
      "metadata": {
        "id": "SoF4ufmc_TbO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the chatbot knowledge base\n",
        "with open('chatbot.txt', 'r', errors='ignore') as f:\n",
        "    raw = f.read().lower()\n",
        "\n",
        "# Tokenize the text\n",
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "word_tokens = nltk.word_tokenize(raw)\n",
        "\n",
        "# Lemmatizer\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
      ],
      "metadata": {
        "id": "XOc3-b2l8Ykk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Greeting inputs and responses\n",
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\")\n",
        "GREETING_RESPONSES = [\n",
        "    \"Hi there! How can I help you?\",\n",
        "    \"Hello! Ask me anything.\",\n",
        "    \"Hey! Ready to chat?\",\n",
        "    \"Greetings! What would you like to know?\"\n",
        "]\n",
        "\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)\n",
        "\n",
        "# Known question-answer pairs\n",
        "KNOWN_RESPONSES = {\n",
        "    \"how are you\": \"I'm just a bot, but I'm doing great! How can I help you?\",\n",
        "    \"what is your name\": \"I am a friendly chatbot created with Python and NLTK.\",\n",
        "    \"who created you\": \"I was built by developers using Python and NLTK.\",\n",
        "    \"what can you do\": \"I can chat with you, answer basic questions, and share some fun info!\"\n",
        "}\n",
        "\n",
        "def check_known_responses(user_input):\n",
        "    for question, answer in KNOWN_RESPONSES.items():\n",
        "        if question in user_input:\n",
        "            return answer\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "3JRrRWGm83kt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    # Check for known responses first\n",
        "    known_answer = check_known_responses(user_response)\n",
        "    if known_answer:\n",
        "        return known_answer\n",
        "\n",
        "    # Use cosine similarity as a fallback\n",
        "    robo_response = ''\n",
        "    sent_tokens.append(user_response)\n",
        "    vectorizer = CountVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tf = vectorizer.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tf[-1], tf)\n",
        "    idx = vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "\n",
        "    if req_tfidf == 0:\n",
        "        robo_response = \"I'm sorry! I didn't quite get that. Could you rephrase?\"\n",
        "    else:\n",
        "        robo_response = sent_tokens[idx]\n",
        "\n",
        "    sent_tokens.remove(user_response)\n",
        "    return robo_response\n"
      ],
      "metadata": {
        "id": "WtsJh9fo86-c"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot():\n",
        "    print(\"BOT: Hello! I am your chatbot. Type 'bye' to exit.\")\n",
        "    while True:\n",
        "        user_response = input(\"You: \").lower()\n",
        "        if user_response != 'bye':\n",
        "            if user_response in ('thanks', 'thank you'):\n",
        "                print(\"BOT: You're welcome!\")\n",
        "                break\n",
        "            else:\n",
        "                if greeting(user_response) is not None:\n",
        "                    print(\"BOT:\", greeting(user_response))\n",
        "                else:\n",
        "                    print(\"BOT:\", response(user_response))\n",
        "        else:\n",
        "            print(\"BOT: Bye! Have a great day!\")\n",
        "            break\n",
        "\n",
        "chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfyCTjhQ89rm",
        "outputId": "70edbe6c-907f-4c54-a087-0010198ae048"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: Hello! I am your chatbot. Type 'bye' to exit.\n",
            "You: hi\n",
            "BOT: Hello! Ask me anything.\n",
            "You: how are you\n",
            "BOT: I'm just a bot, but I'm doing great! How can I help you?\n",
            "You: what is your name\n",
            "BOT: I am a friendly chatbot created with Python and NLTK.\n",
            "You: tell me about python\n",
            "BOT: tell me about python\n",
            "python is a high-level, interpreted programming language known for its simplicity and readability.\n",
            "You: tell me about nltk\n",
            "BOT: tell me about nltk\n",
            "nltk is a leading platform for building python programs to work with human language data.\n",
            "You: bye\n",
            "BOT: Bye! Have a great day!\n"
          ]
        }
      ]
    }
  ]
}